{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h-q2yt4t_KJr"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xbvKPTtM_3KU",
    "outputId": "0cf64ed8-4214-448b-e472-b43b4d9593dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 1.x selected.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2X2j1GsFANB4",
    "outputId": "5c635956-ee9c-4c94-c190-c03b530944cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow  version: 1.15.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "print('TensorFlow  version: {}'.format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "niq3DNFeCZTg"
   },
   "outputs": [],
   "source": [
    "%%capture \n",
    "# Install AmpliGraph library\n",
    "! pip install ampligraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c0-kixokC3vc",
    "outputId": "f9781870-80ca-4326-de5d-1b2f93cef892"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ampligraph version: 1.4.0\n"
     ]
    }
   ],
   "source": [
    "# All imports used in this tutorial \n",
    "%tensorflow_version 1.x\n",
    "import ampligraph\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from ampligraph.datasets import load_fb15k_237\n",
    "from ampligraph.evaluation import train_test_split_no_unseen, evaluate_performance, mr_score, mrr_score, hits_at_n_score\n",
    "from ampligraph.discovery import query_topn, discover_facts, find_clusters\n",
    "from ampligraph.latent_features import TransE, ComplEx, HolE, DistMult, ConvE, ConvKB\n",
    "from ampligraph.utils import save_model, restore_model\n",
    "\n",
    "def display_aggregate_metrics(ranks):\n",
    "    print('Mean Rank:', mr_score(ranks)) \n",
    "    print('Mean Reciprocal Rank:', mrr_score(ranks)) \n",
    "    print('Hits@1:', hits_at_n_score(ranks, 1))\n",
    "    print('Hits@10:', hits_at_n_score(ranks, 10))\n",
    "    print('Hits@100:', hits_at_n_score(ranks, 100))\n",
    "\n",
    "print('Ampligraph version: {}'.format(ampligraph.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c83HS3xZDHPi"
   },
   "source": [
    "# Loading data, Create training, validation and test splits\n",
    "\n",
    "Let's use the [`train_test_split_no_unseen`](https://docs.ampligraph.org/en/1.3.1/generated/ampligraph.evaluation.train_test_split_no_unseen.html?#train-test-split-no-unseen) function provided by Ampligraph to create the training, validation and test splits. \n",
    "\n",
    "This API ensures that the test and validation splits contains triples whose entities are \"seen\" during training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "VB-9k149_ltW",
    "outputId": "8762ef92-0d23-4c76-ba6b-20013b1260fe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>predicate</th>\n",
       "      <th>object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Released in</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jumanji</td>\n",
       "      <td>Released in</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>Released in</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Released in</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>Released in</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       subject    predicate object\n",
       "0                    Toy Story  Released in   1995\n",
       "1                      Jumanji  Released in   1995\n",
       "2             Grumpier Old Men  Released in   1995\n",
       "3            Waiting to Exhale  Released in   1995\n",
       "4  Father of the Bride Part II  Released in   1995"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load('Knowledge_Graph /movielens_triplets.npy',allow_pickle=True)\n",
    "dataset  = pd.DataFrame(data,columns = ['subject', 'predicate', 'object'])\n",
    "dataset = dataset.applymap(str)\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VDqarWHmIyNj",
    "outputId": "541b8226-a1c3-425a-c83d-334e4f7f8f06"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2028829, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3W8HtMF8XcAK"
   },
   "outputs": [],
   "source": [
    "# create train/test/valid splits, train the model and evaluate using train_test_split_no_unseen API\n",
    "from ampligraph.evaluation import train_test_split_no_unseen\n",
    "# get the validation set of size 500\n",
    "test_train, X_valid = train_test_split_no_unseen(dataset.values, 5000, seed=0)\n",
    "\n",
    "# get the test set of size 1000 from the remaining triples\n",
    "X_train, X_test = train_test_split_no_unseen(test_train, 20000, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TarnQ6a-ipOX",
    "outputId": "dfc80e66-b530-41aa-8e74-a87932640435"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2003829,)"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:,2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3F_i5nC-h7hn",
    "outputId": "52dfe0d1-c350-4b57-f832-04e0dab455ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9869,)\n",
      "(3663,)\n",
      "(3782,)\n",
      "9896\n",
      "#########\n",
      "(2713,)\n",
      "(1293,)\n",
      "(1271,)\n",
      "3971\n",
      "#########\n",
      "(4750,)\n",
      "(2241,)\n",
      "(2344,)\n",
      "6998\n",
      "7450\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(X_train[:,0]).shape)\n",
    "print(np.unique(X_train[:,1]).shape)\n",
    "print(np.unique(X_train[:,2]).shape)\n",
    "print(len(set(np.unique(X_train[:,0])).union(np.unique(X_train[:,2]))))\n",
    "print('#########')\n",
    "print(np.unique(X_valid[:,0]).shape)\n",
    "print(np.unique(X_valid[:,1]).shape)\n",
    "print(np.unique(X_valid[:,2]).shape)\n",
    "print(len(set(np.unique(X_valid[:,0])).union(np.unique(X_valid[:,2]))))\n",
    "print('#########')\n",
    "print(np.unique(X_test[:,0]).shape)\n",
    "print(np.unique(X_test[:,1]).shape)\n",
    "print(np.unique(X_test[:,2]).shape)\n",
    "print(len(set(np.unique(X_test[:,0])).union(np.unique(X_test[:,2]))))\n",
    "print(len(set(np.unique(X_valid[:,0])).union(np.unique(X_valid[:,2])).union(np.unique(X_test[:,0])).union(np.unique(X_test[:,2]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2m9vZYwPo5EY",
    "outputId": "ba278cf0-e640-43f5-d9fd-fba94d11da2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13533\n"
     ]
    }
   ],
   "source": [
    "print(len(set(dataset.predicate).union(dataset.subject)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FLoLwSby-fy_"
   },
   "source": [
    "### TransE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S6KZ7A71XuP-",
    "outputId": "d8f8296a-d2aa-466d-853c-20323e9fcc05"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average TransE Loss:   0.059722: 100%|██████████| 100/100 [07:12<00:00,  4.32s/epoch]\n",
      "100%|██████████| 20000/20000 [03:27<00:00, 96.34it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total triples: (2028829, 3)\n",
      "Size of train: (2003829, 3)\n",
      "Size of valid: (5000, 3)\n",
      "Size of test: (20000, 3)\n",
      "Size of ranks: (20000, 2)\n",
      "Mean Rank: 1568.195425\n",
      "Mean Reciprocal Rank: 0.1424676283072877\n",
      "Hits@1: 0.07945\n",
      "Hits@10: 0.245625\n",
      "Hits@100: 0.36035\n"
     ]
    }
   ],
   "source": [
    "# Train a KGE model\n",
    "model = TransE(k=300, \n",
    "               epochs=100, \n",
    "               eta=1, \n",
    "               loss='multiclass_nll', \n",
    "               initializer='xavier', initializer_params={'uniform': False},\n",
    "               regularizer='LP', regularizer_params= {'lambda': 0.001, 'p': 3},\n",
    "               optimizer= 'adam', optimizer_params= {'lr': 0.0001}, \n",
    "               seed= 0, batches_count= 100, verbose=True)\n",
    "\n",
    "model.fit(X_train)\n",
    "\n",
    "\n",
    "from ampligraph.utils import save_model, restore_model\n",
    "\n",
    "# create the filter \n",
    "X_filter = np.concatenate([X_train, X_valid, X_test], 0)\n",
    "\n",
    "# compute ranks\n",
    "ranks = evaluate_performance(X_test, \n",
    "                             model=model, \n",
    "                             filter_triples=X_filter)\n",
    "\n",
    "# ranks are computed per triple\n",
    "print('Total triples:', dataset.shape)\n",
    "print('Size of train:', X_train.shape)\n",
    "print('Size of valid:', X_valid.shape)\n",
    "print('Size of test:', X_test.shape)\n",
    "print('Size of ranks:', ranks.shape)\n",
    "\n",
    "\n",
    "display_aggregate_metrics(ranks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DistMult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d9TSQcLRqRJ9",
    "outputId": "8550581a-9845-4b88-e546-51031b579705"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average DistMult Loss:   0.035177: 100%|██████████| 100/100 [08:05<00:00,  4.86s/epoch]\n",
      "100%|██████████| 20000/20000 [03:12<00:00, 103.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total triples: (2028829, 3)\n",
      "Size of train: (2003829, 3)\n",
      "Size of valid: (5000, 3)\n",
      "Size of test: (20000, 3)\n",
      "Size of ranks: (20000, 2)\n",
      "Mean Rank: 1021.1678\n",
      "Mean Reciprocal Rank: 0.16830689257961962\n",
      "Hits@1: 0.09715\n",
      "Hits@10: 0.2794\n",
      "Hits@100: 0.39375\n"
     ]
    }
   ],
   "source": [
    "model = DistMult(k=300, epochs=100, eta=1, loss='multiclass_nll', \n",
    "                initializer='xavier', initializer_params={'uniform': False},\n",
    "                regularizer='LP', regularizer_params= {'lambda': 0.0001, 'p': 3},\n",
    "                optimizer= 'adam', optimizer_params= {'lr': 0.001}, \n",
    "                seed= 0, batches_count= 100, verbose=True)\n",
    "\n",
    "model.fit(X_train)\n",
    "\n",
    "X_filter = np.concatenate([X_train, X_valid, X_test], 0)\n",
    "ranks = evaluate_performance(X_test, \n",
    "                             model=model,\n",
    "                             filter_triples=X_filter,\n",
    "                             corrupt_side='s,o',\n",
    "                             ranking_strategy='worst')\n",
    "# ranks are computed per triple\n",
    "print('Total triples:', dataset.shape)\n",
    "print('Size of train:', X_train.shape)\n",
    "print('Size of valid:', X_valid.shape)\n",
    "print('Size of test:', X_test.shape)\n",
    "print('Size of ranks:', ranks.shape)\n",
    "display_aggregate_metrics(ranks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z4-Y-I8eqSpu",
    "outputId": "6551a82c-31bc-4bf1-c3ab-2662b2bb717f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of entity embeddings: (9896, 300)\n",
      "Size of entity embeddings: (3663, 300)\n"
     ]
    }
   ],
   "source": [
    "print('Size of entity embeddings:', model.ent_emb.shape)\n",
    "print('Size of entity embeddings:', model.rel_emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tiFW7AJ0eE0F",
    "outputId": "c320d006-0fd4-4f91-c181-182731d4316f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9869"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(X_train[:,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AgFKn4CRqTzX"
   },
   "source": [
    "### Complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5pPOqJ1-qV46",
    "outputId": "2d1d88b2-471d-4dc8-f292-96e890746ea9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average ComplEx Loss:   0.027870: 100%|██████████| 100/100 [34:50<00:00, 20.90s/epoch]\n",
      "100%|██████████| 20000/20000 [17:22<00:00, 19.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total triples: (2028829, 3)\n",
      "Size of train: (2003829, 3)\n",
      "Size of valid: (5000, 3)\n",
      "Size of test: (20000, 3)\n",
      "Size of ranks: (20000, 2)\n",
      "Mean Rank: 1081.8704\n",
      "Mean Reciprocal Rank: 0.16274188244918117\n",
      "Hits@1: 0.09535\n",
      "Hits@10: 0.27\n",
      "Hits@100: 0.360525\n"
     ]
    }
   ],
   "source": [
    "model = ComplEx(k=300, epochs=100, eta=1, loss='multiclass_nll', \n",
    "                initializer='xavier', initializer_params={'uniform': False},\n",
    "                regularizer='LP', regularizer_params= {'lambda': 0.0001, 'p': 3},\n",
    "                optimizer= 'adam', optimizer_params= {'lr': 0.001}, \n",
    "                seed= 0, batches_count= 100, verbose=True)\n",
    "\n",
    "model.fit(X_train)\n",
    "\n",
    "X_filter = np.concatenate([X_train, X_valid, X_test], 0)\n",
    "\n",
    "ranks = evaluate_performance(X_test, \n",
    "                             model=model,\n",
    "                             filter_triples=X_filter,\n",
    "                             corrupt_side='s,o',\n",
    "                             ranking_strategy='worst')\n",
    "# ranks are computed per triple\n",
    "print('Total triples:', dataset.shape)\n",
    "print('Size of train:', X_train.shape)\n",
    "print('Size of valid:', X_valid.shape)\n",
    "print('Size of test:', X_test.shape)\n",
    "print('Size of ranks:', ranks.shape)\n",
    "display_aggregate_metrics(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KIrjD-dPqWoN",
    "outputId": "7042655f-ac16-4134-9b94-a2b1cfe7f3ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of entity embeddings: (9896, 600)\n",
      "Size of entity embeddings: (3663, 600)\n"
     ]
    }
   ],
   "source": [
    "print('Size of entity embeddings:', model.ent_emb.shape)\n",
    "print('Size of entity embeddings:', model.rel_emb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5T6x2IYr5Uxz"
   },
   "source": [
    "## HolE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "UDSvi9PM5cdv",
    "outputId": "ce7e2352-4c44-4924-f7ee-1c0b43b6bbf3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average HolE Loss:   0.073980: 100%|██████████| 100/100 [35:12<00:00, 21.13s/epoch]\n",
      "100%|██████████| 20000/20000 [11:51<00:00, 28.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total triples: (2028829, 3)\n",
      "Size of train: (2003829, 3)\n",
      "Size of valid: (5000, 3)\n",
      "Size of test: (20000, 3)\n",
      "Size of ranks: (20000, 2)\n",
      "Mean Rank: 1001.13915\n",
      "Mean Reciprocal Rank: 0.18144388934051395\n",
      "Hits@1: 0.108625\n",
      "Hits@10: 0.297\n",
      "Hits@100: 0.416925\n"
     ]
    }
   ],
   "source": [
    "model = HolE(k=300, epochs=100, eta=1, loss='multiclass_nll', \n",
    "                initializer='xavier', initializer_params={'uniform': False},\n",
    "                regularizer='LP', regularizer_params= {'lambda': 0.0001, 'p': 3},\n",
    "                optimizer= 'adam', optimizer_params= {'lr': 0.001}, \n",
    "                seed= 0, batches_count= 100, verbose=True)\n",
    "\n",
    "model.fit(X_train)\n",
    "\n",
    "X_filter = np.concatenate([X_train, X_valid, X_test], 0)\n",
    "\n",
    "ranks = evaluate_performance(X_test, \n",
    "                             model=model,\n",
    "                             filter_triples=X_filter,\n",
    "                             corrupt_side='s,o',\n",
    "                             ranking_strategy='worst')\n",
    "# ranks are computed per triple\n",
    "print('Total triples:', dataset.shape)\n",
    "print('Size of train:', X_train.shape)\n",
    "print('Size of valid:', X_valid.shape)\n",
    "print('Size of test:', X_test.shape)\n",
    "print('Size of ranks:', ranks.shape)\n",
    "display_aggregate_metrics(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k56B9fAQ5ckQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4u_YxZGRqYWk"
   },
   "source": [
    "## Convolutional models\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1xP_BA1Gmto3"
   },
   "source": [
    "### ConvKB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0f5wQM8Lqapv"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = ConvKB(k=300, epochs=100, eta=1, loss='multiclass_nll', \n",
    "                initializer='xavier', initializer_params={'uniform': False},\n",
    "                regularizer='LP', regularizer_params= {'lambda': 0.0001, 'p': 3},\n",
    "                optimizer= 'adam', optimizer_params= {'lr': 0.001}, \n",
    "                seed= 0, \n",
    "                batches_count= 100, # Goes OOM (ResourceExhaustedError) if batch count is 1\n",
    "                verbose=True)\n",
    "\n",
    "\n",
    "model.fit(X_train)\n",
    "X_filter = np.concatenate([X_train, X_valid, X_test], 0)\n",
    "ranks = evaluate_performance(X_test, \n",
    "                             model=model,\n",
    "                             filter_triples=X_filter,\n",
    "                             corrupt_side='s,o',\n",
    "                             ranking_strategy='worst')\n",
    "# ranks are computed per triple\n",
    "print('Total triples:', dataset.shape)\n",
    "print('Size of train:', X_train.shape)\n",
    "print('Size of valid:', X_valid.shape)\n",
    "print('Size of test:', X_test.shape)\n",
    "print('Size of ranks:', ranks.shape)\n",
    "display_aggregate_metrics(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N_0rphB0_9MU"
   },
   "outputs": [],
   "source": [
    "X_filter = np.concatenate([X_train, X_valid, X_test], 0)\n",
    "ranks = evaluate_performance(X_test, \n",
    "                             model=model,\n",
    "                             filter_triples=X_filter,\n",
    "                             corrupt_side='s,o',\n",
    "                             ranking_strategy='worst')\n",
    "display_aggregate_metrics(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "65mg1RtdqcsW"
   },
   "outputs": [],
   "source": [
    "print('Size of entity embeddings:', model.ent_emb.shape)\n",
    "print('Size of entity embeddings:', model.rel_emb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d62IQMi4m95u"
   },
   "source": [
    "### ConvE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jev0TITPqfFg"
   },
   "outputs": [],
   "source": [
    "from ampligraph.evaluation import train_test_split_no_unseen\n",
    "# get the validation set of size 500\n",
    "test_train, X_valid = train_test_split_no_unseen(dataset.values, 5000, seed=0)\n",
    "\n",
    "# get the test set of size 1000 from the remaining triples\n",
    "X_train, X_test = train_test_split_no_unseen(test_train, 20000, seed=0)\n",
    "model = ConvE(k=150, epochs=100, loss='bce', \n",
    "                initializer='xavier', initializer_params={'uniform': False},\n",
    "                regularizer='LP', regularizer_params= {'lambda': 0.001, 'p': 3},\n",
    "                optimizer= 'adam', optimizer_params= {'lr': 0.001}, \n",
    "                seed= 0, batches_count= 20, verbose=True)\n",
    "\n",
    "model.fit(X_train)\n",
    "X_filter = np.concatenate([X_train, X_valid, X_test], 0)\n",
    "ranks = evaluate_performance(X_test, \n",
    "                             model=model,\n",
    "                             filter_triples=X_filter,\n",
    "                             corrupt_side='o',\n",
    "                             ranking_strategy='worst')\n",
    "# ranks are computed per triple\n",
    "print('Total triples:', dataset.shape)\n",
    "print('Size of train:', X_train.shape)\n",
    "print('Size of valid:', X_valid.shape)\n",
    "print('Size of test:', X_test.shape)\n",
    "print('Size of ranks:', ranks.shape)\n",
    "display_aggregate_metrics(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "75svVDO5qgMo"
   },
   "outputs": [],
   "source": [
    "print('Size of entity embeddings:', model.ent_emb.shape)\n",
    "print('Size of entity embeddings:', model.rel_emb.shape)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "KGE_TPU .ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
